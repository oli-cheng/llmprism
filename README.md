# ğŸ”· LLMPrism

**A privacy-first, multi-model AI cockpit for power users.**

Compare responses from OpenAI, Anthropic, and Google Gemini side-by-side â€” all from a single prompt. No server. No telemetry. Your keys never leave your browser.

---

## âœ¨ Why LLMPrism?

Choosing the right LLM for a task shouldn't require juggling browser tabs. LLMPrism lets you run the same prompt against multiple models concurrently, compare outputs in a clean three-pane UI, and merge the best parts into a polished final document â€” all without sending data to any intermediary server.

### Key Capabilities

| Feature | Details |
|---|---|
| **Concurrent Multi-Run** | Fire a prompt at 2â€“3 models simultaneously with per-provider progress and cancel |
| **Side-by-Side Comparison** | Tabbed response panes showing provider, model, token count, latency, and estimated cost |
| **Merge Workflow** | Select text from any response and insert it into a final document at your cursor position |
| **Demo Mode** | Full interactive demo with realistic mock responses â€” no API keys required |
| **Routing Rules Engine** | JSON-validated rules to auto-select models based on prompt characteristics |
| **Encrypted Key Vault** | API keys encrypted with AES-256-GCM via Web Crypto API; passphrase never stored |
| **Local-First Storage** | All data persisted in `localStorage`. Works offline. Zero server dependencies |
| **Context Packs** | Attach reusable system prompts and context snippets to any thread |

---

## ğŸš€ 60-Second Demo Script

> No API keys needed â€” Demo Mode uses realistic mock responses.

1. **Open the app** â†’ the onboarding dialog appears on first visit
2. **Enable Demo Mode** â†’ toggle "Demo Mode" in onboarding or Settings
3. **Create a workspace** â†’ click "+ Workspace" in the sidebar
4. **Create a thread** â†’ click "+ Thread" inside your workspace
5. **Type a prompt** â†’ e.g. *"Compare three approaches to caching in a web app"*
6. **Select 2â€“3 models** â†’ pick from OpenAI, Anthropic, and Gemini in the toolbar
7. **Click Run** â†’ watch concurrent responses stream in with latency + token stats
8. **Compare** â†’ switch between response tabs (A / B / C) to review each model's output
9. **Merge** â†’ select text from a response and click "Insert into Final" to compose your document
10. **Export** â†’ click Export to download the final document as Markdown

**Total time: ~60 seconds.** You've just experienced multi-model comparison, merge workflow, and export â€” all running locally in your browser.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React UI  â”‚â”€â”€â”€â”€â–¶â”‚  AppContext â”‚â”€â”€â”€â”€â–¶â”‚  Adapters  â”‚â”€â”€â”€â”€â–¶â”‚  Provider    â”‚
â”‚  Components â”‚     â”‚   (State)  â”‚     â”‚ (Normalize) â”‚     â”‚  APIs        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”Œâ”€â”€â”€â”€â”      â”‚
                                                           â”‚  â”‚OAI â”‚      â”‚
                           â–²                               â”‚  â”œâ”€â”€â”€â”€â”¤      â”‚
                           â”‚                               â”‚  â”‚ANT â”‚      â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                        â”‚  â”œâ”€â”€â”€â”€â”¤      â”‚
                    â”‚  Encrypted  â”‚                        â”‚  â”‚GEM â”‚      â”‚
                    â”‚ localStorageâ”‚                        â”‚  â””â”€â”€â”€â”€â”˜      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Engineering Highlights

- **Provider Adapter Pattern** â€” Unified interface for OpenAI, Anthropic, and Gemini. Adding a new provider is one file.
- **Concurrent Execution** â€” `Promise.all` with per-provider `AbortController`. Cancel one model without affecting others.
- **Encrypted Key Storage** â€” AES-256-GCM encryption via the Web Crypto API. Your passphrase is never persisted.
- **Privacy by Design** â€” No analytics, no tracking, no server. Data only leaves your browser when you call a provider API.
- **Routing Rules Engine** â€” JSON-schema-validated rules with simulation. Test routing logic before execution.
- **Self-Check Suite** â€” Built-in automated QA (Cmd/Ctrl+Shift+P â†’ "Run self-check") verifies the full workflow end-to-end.

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|---|---|
| Framework | React 18 + TypeScript |
| Build | Vite |
| Styling | Tailwind CSS + Radix UI (shadcn/ui) |
| State | React Context + `localStorage` |
| Crypto | Web Crypto API (AES-256-GCM) |
| Layout | `react-resizable-panels` |

---

## ğŸ“¦ Getting Started

```sh
# Clone the repository
git clone <YOUR_GIT_URL>
cd llmprism

# Install dependencies
npm install

# Start the dev server
npm run dev
```

Open [http://localhost:5173](http://localhost:5173) and enable **Demo Mode** to explore without API keys.

### Using Real API Keys

1. Open **Settings** (gear icon in the header)
2. Disable Demo Mode
3. Enter your API keys for OpenAI, Anthropic, and/or Google Gemini
4. Keys are encrypted locally â€” they never leave your browser

---

## ğŸ“„ License

MIT

---

<p align="center">
  <strong>Built as a portfolio demonstration</strong><br/>
  <em>Privacy-first â€¢ Local-only â€¢ Zero external dependencies for core functionality</em>
</p>
